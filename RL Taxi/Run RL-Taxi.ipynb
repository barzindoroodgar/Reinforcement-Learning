{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "import os\n",
    "import reinforcement_learning as rl\n",
    "from taxi_environment import *\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "776965\n",
      "130823\n"
     ]
    }
   ],
   "source": [
    "Qt = None\n",
    "pi = None\n",
    "\n",
    "# load trained Q table and policy from file\n",
    "Qt, pi = rl.read_data(filename='q_data_3grids_2019-05-17 19-47-45.pkl')\n",
    "print(len(Qt.table))\n",
    "print(len(pi.sa_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Small Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episodes: 21\n"
     ]
    }
   ],
   "source": [
    "# test the trained model by choosing the best Q(s,a) using pi.get_maxQ_action\n",
    "# initialize environment\n",
    "gui = tk.Tk()\n",
    "grid = small_grid\n",
    "env = Environment(gui=gui, grid=grid)\n",
    "\n",
    "# get initial <s1, a1, s2, r>\n",
    "s1 = get_state(env)\n",
    "a1 = 'e'\n",
    "s2 = rl.state()\n",
    "r = 0     \n",
    "episode = 0\n",
    "\n",
    "while not env.task_complete:\n",
    "    episode += 1\n",
    "    # choose action to take in state s1\n",
    "    allowed_actions = env.get_allowed_actions()\n",
    "    a1 = pi.get_maxQ_action(s=s1, allowed_actions=allowed_actions)\n",
    "    r = env.execute_action(a1)\n",
    "\n",
    "    # get state s2\n",
    "    s2 = get_state(env)\n",
    "    s1 = s2  \n",
    "\n",
    "    # update Tkinter gui\n",
    "    time.sleep(0.2)\n",
    "    gui.update_idletasks()\n",
    "    gui.update()\n",
    "\n",
    "time.sleep(1)\n",
    "gui.quit()\n",
    "gui.destroy()\n",
    "print(\"episodes: %d\" % episode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Big Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episodes: 42\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# initialize environment\n",
    "gui = tk.Tk()\n",
    "grid = big_grid\n",
    "env = Environment(gui=gui, grid=grid)\n",
    "\n",
    "# get initial <s1, a1, s2, r>\n",
    "s1 = get_state(env)\n",
    "a1 = 'e'\n",
    "s2 = rl.state()\n",
    "r = 0     \n",
    "episode = 0\n",
    "\n",
    "while not env.task_complete:\n",
    "    episode += 1\n",
    "    # choose action to take in state s1\n",
    "    allowed_actions = env.get_allowed_actions()\n",
    "    a1 = pi.get_maxQ_action(s=s1, allowed_actions=allowed_actions)\n",
    "    r = env.execute_action(a1)\n",
    "\n",
    "    # get state s2\n",
    "    s2 = get_state(env)\n",
    "    s1 = s2  \n",
    "\n",
    "    # update Tkinter gui\n",
    "    time.sleep(0.2)\n",
    "    gui.update_idletasks()\n",
    "    gui.update()\n",
    "\n",
    "time.sleep(1)\n",
    "gui.quit()\n",
    "gui.destroy()\n",
    "print(\"episodes: %d\" % episode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Huge Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episodes: 51\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# initialize environment\n",
    "gui = tk.Tk()\n",
    "grid = huge_grid\n",
    "env = Environment(gui=gui, grid=grid)\n",
    "\n",
    "# get initial <s1, a1, s2, r>\n",
    "s1 = get_state(env)\n",
    "a1 = 'e'\n",
    "s2 = rl.state()\n",
    "r = 0     \n",
    "episode = 0\n",
    "\n",
    "while not env.task_complete:\n",
    "    episode += 1\n",
    "    # choose action to take in state s1\n",
    "    allowed_actions = env.get_allowed_actions()\n",
    "    a1 = pi.get_maxQ_action(s=s1, allowed_actions=allowed_actions)\n",
    "    r = env.execute_action(a1)\n",
    "\n",
    "    # get state s2\n",
    "    s2 = get_state(env)\n",
    "    s1 = s2  \n",
    "\n",
    "    # update Tkinter gui\n",
    "    time.sleep(0.2)\n",
    "    gui.update_idletasks()\n",
    "    gui.update()\n",
    "\n",
    "time.sleep(1)\n",
    "gui.quit()\n",
    "gui.destroy()\n",
    "print(\"episodes: %d\" % episode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
